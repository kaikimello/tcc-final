{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalando o scikit-surprise\n",
        "!pip3 install scikit-surprise"
      ],
      "metadata": {
        "id": "nppLWKCTjbSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from functools import reduce \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import cross_validate, KFold\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "HKOsln3j5okj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RECOMENDADOR BASEADO EM CONTEÚDO**"
      ],
      "metadata": {
        "id": "mMzhoXOXCjnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o dataset movies_metadata\n",
        "md_filmes = pd.read_csv('movies_metadata.csv')\n",
        "# Exibindo metadados dos filmes\n",
        "md_filmes"
      ],
      "metadata": {
        "id": "L3-oZGn0E93I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes['genres'] = md_filmes['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance (x, list) else [])"
      ],
      "metadata": {
        "id": "6nFewWcSyQPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes['year'] = pd.to_datetime(md_filmes['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)"
      ],
      "metadata": {
        "id": "rooKTmY4755A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes.head()"
      ],
      "metadata": {
        "id": "u5ZmWfK9yeQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando dataset links_small\n",
        "links_small = pd.read_csv('links_small.csv', dtype={'movieId':\"Int64\",'imdbId':\"Int64\",'tmdbId':\"Int64\"})\n",
        "# Vai ser usado no KNN\n",
        "ds_links = links_small\n",
        "# Converte o tipo da coluna, filtra os não nulos e cria uma serie com os valores de tmdbId\n",
        "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
        "# Exibindo a serie \n",
        "links_small"
      ],
      "metadata": {
        "id": "qilcKwCOCrnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Essas linhas possuem dados maus formatados, por isso foram removidas,\n",
        "# o rest_index é para remover a coluna de index que foi criada, pois a \n",
        "# mesma estava fora de ordem \n",
        "md_filmes = md_filmes.drop([19730, 29503, 35587])\n",
        "# Exibindo metadados dos filmes\n",
        "md_filmes"
      ],
      "metadata": {
        "id": "tuLQGZU8FVB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes[md_filmes['title'] == 'Black Gold'][['popularity']]"
      ],
      "metadata": {
        "id": "pj21rFlBbSlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convete o tipo da coluna \n",
        "md_filmes['id'] = md_filmes['id'].astype('int')"
      ],
      "metadata": {
        "id": "q3qfL7z7GNPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convete o tipo da coluna popularidade para float\n",
        "md_filmes['popularity'] = md_filmes['popularity'].astype('float')"
      ],
      "metadata": {
        "id": "abdmJXc1i-BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para conseguir remover as duplicatas \n",
        "md_filmes['genres'] = md_filmes['genres'].astype('str')"
      ],
      "metadata": {
        "id": "wZaQy6QPq4Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenando coluna de popularidade\n",
        "md_filmes = md_filmes.sort_values('popularity', ascending=False).drop_duplicates().sort_index()"
      ],
      "metadata": {
        "id": "UjhbvptWh-dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes"
      ],
      "metadata": {
        "id": "_Y3MK5kSBNd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo os duplicados que contém mesmo valore de id, imdb_id, title\n",
        "md_filmes = md_filmes.drop_duplicates(subset=['id', 'imdb_id', 'title'])"
      ],
      "metadata": {
        "id": "e25yDZ20sOPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convete o tipo da coluna genero para list\n",
        "md_filmes['genres'] = md_filmes['genres'].apply(literal_eval)"
      ],
      "metadata": {
        "id": "Ik9r7GZblY23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes[md_filmes['title'] == 'Black Gold'][['popularity']]"
      ],
      "metadata": {
        "id": "osyTODXYbExi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***RECOMENDADOR BASEADO EM METADADOS DOS FILMES***"
      ],
      "metadata": {
        "id": "tKr8twK6vr3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando dados dos credits  \n",
        "credits = pd.read_csv('credits.csv')\n",
        "# Carregando dados dos keywords  \n",
        "keywords = pd.read_csv('keywords.csv')"
      ],
      "metadata": {
        "id": "GxR_XKjJwIho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte o tipo da coluna para int\n",
        "keywords['id'] = keywords['id'].astype('int')\n",
        "credits['id'] = credits['id'].astype('int')\n",
        "md_filmes['id'] = md_filmes['id'].astype('int')"
      ],
      "metadata": {
        "id": "Ue5v0Bv-wmF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes.shape"
      ],
      "metadata": {
        "id": "xWJJw7wJwm_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo a junção dos Dataframes de filmes com creditos e palavras chave \n",
        "md_filmes = md_filmes.merge(credits, on='id')\n",
        "md_filmes = md_filmes.merge(keywords, on='id')"
      ],
      "metadata": {
        "id": "S7qN9-vOzvk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para conseguir remover as duplicatas \n",
        "md_filmes['genres'] = md_filmes['genres'].astype('str')"
      ],
      "metadata": {
        "id": "0t1Ke2sEkNbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo duplicados\n",
        "md_filmes = md_filmes.drop_duplicates()"
      ],
      "metadata": {
        "id": "AKsVqa8Pkh1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_filmes"
      ],
      "metadata": {
        "id": "PIFv7NF6UPzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convete o tipo da coluna genero para list\n",
        "md_filmes['genres'] = md_filmes['genres'].apply(literal_eval)"
      ],
      "metadata": {
        "id": "HvL0SzVXnB35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colete todos os metadados para filmes no conjunto de dados links_small\n",
        "# Filtre os filmes cujo id está presente no arquivo links.csv e armazene em smd\n",
        "# .isin -> Se cada elemento no DataFrame está contido em valores.\n",
        "# Similar movie data - smd\n",
        "smd = md_filmes[md_filmes['id'].isin(links_small)]\n",
        "# ds_filmes vai ser usado no KNN\n",
        "ds_filmes = smd\n",
        "smd.shape"
      ],
      "metadata": {
        "id": "dEywCQNs1UAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd"
      ],
      "metadata": {
        "id": "19slSaMP4iOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd['cast'] = smd['cast'].apply(literal_eval)"
      ],
      "metadata": {
        "id": "cA-Tsqzc4qaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd['crew'] = smd['crew'].apply(literal_eval)"
      ],
      "metadata": {
        "id": "vymC8esb46G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd['keywords'] = smd['keywords'].apply(literal_eval)"
      ],
      "metadata": {
        "id": "a9E0bjfs5j7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria nova coluna com tamanho do cast\n",
        "smd['cast_size'] = smd['cast'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "4jNiirz852Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria nova coluna com tamanho do crew\n",
        "smd['crew_size'] = smd['crew'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "KPLm0RZe6ab6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd.head()"
      ],
      "metadata": {
        "id": "C2mqSc-25ehQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obter_diretor(x):\n",
        "  for i in x:\n",
        "    if i['job'] == 'Director':\n",
        "      return i['name']\n",
        "  return np.nan"
      ],
      "metadata": {
        "id": "UROxhu__5ed0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd['director'] = smd['crew'].apply(obter_diretor)"
      ],
      "metadata": {
        "id": "VNIkDvhL8wl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organiza o nome do cast\n",
        "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
      ],
      "metadata": {
        "id": "l9pci5iG9xPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona os 3 principais atores \n",
        "smd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)"
      ],
      "metadata": {
        "id": "fmoRnsjf_CYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd.head()"
      ],
      "metadata": {
        "id": "-F_PbsiG-wOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smd['keywords'][1]"
      ],
      "metadata": {
        "id": "HCoYiWX5CQMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organiza as palavras chaves numa lista\n",
        "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else []) "
      ],
      "metadata": {
        "id": "4C_T5I7gBeQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove os espaços e deixa tudo minusculo no cast\n",
        "smd['cast'] = smd['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
      ],
      "metadata": {
        "id": "c6BtU09ql34y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte o tipo da coluna do director para string, pega o nome do diretor deixa minusculo e sem espaços\n",
        "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))"
      ],
      "metadata": {
        "id": "XAIr330_pI4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repete 3 vezes o nome do diretor na lista para dar mais peso em relação a todo elenco\n",
        "smd['director'] = smd['director'].apply(lambda x: [x,x, x])"
      ],
      "metadata": {
        "id": "lVg1sz5oq9lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **PALAVRAS-CHAVE**  \n",
        "Será feito um pré-processamento das palavras chaves"
      ],
      "metadata": {
        "id": "XbMeC_EbsSao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smd"
      ],
      "metadata": {
        "id": "86YCWlH-or5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar uma serie palavras chave aplicando ao longo do axis=1 coluna\n",
        "# stack ->retornar um dataframe remodelado, se as colunas tiverem um único nível, a saída é uma Série;\n",
        "# Reseta index em 1 nível\n",
        "palavras_chave = smd.apply(lambda x: pd.Series(x['keywords']), axis=1).stack().reset_index(level=1, drop=True)"
      ],
      "metadata": {
        "id": "vZi65DhSsff-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nomeia a serie\n",
        "palavras_chave.name = 'keyword'"
      ],
      "metadata": {
        "id": "fPG_423y0BAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retorna uma série contendo contagens de valores exclusivos.\n",
        "palavras_chave = palavras_chave.value_counts()\n",
        "\n",
        "#Exibindo as 5 palavras que ocorrem com mais frequencia  \n",
        "palavras_chave[:5]"
      ],
      "metadata": {
        "id": "lRl5u-jBjPgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando somente as palavras que ocorrem mais de uma vez\n",
        "palavras_chave = palavras_chave[palavras_chave > 1]"
      ],
      "metadata": {
        "id": "e1pne_MHlNrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converterndo palavras em seu radical\n",
        "stemmer = SnowballStemmer('english')\n",
        "stemmer.stem('dogs')"
      ],
      "metadata": {
        "id": "ZsAiyuXRnpnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filtrar_palavras_chave(x):\n",
        "  words = []\n",
        "  for i in x:\n",
        "    if i in palavras_chave:\n",
        "      words.append(i)\n",
        "  return words"
      ],
      "metadata": {
        "id": "jdYkIpx7oLsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a função filtrar palavras chaves\n",
        "smd['keywords'] = smd['keywords'].apply(filtrar_palavras_chave)"
      ],
      "metadata": {
        "id": "K-XqXipoo2PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica a lisa de palavras o stemmer que deixa somente o radical\n",
        "smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "metadata": {
        "id": "v2_SM2cYpoP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deixa as palavras minusculas e remove os espaços em palavras compostas \n",
        "smd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
      ],
      "metadata": {
        "id": "5T5TqoTYsIOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando sopa de palavras unindo as colunas \n",
        "smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres']"
      ],
      "metadata": {
        "id": "I7JkM219sdaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Une as palavras da lista separando por espaços\n",
        "smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "hkaGmi2QttX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ele é usado para transformar um determinado texto em um vetor com base na frequência (contagem) \n",
        "# de cada palavra que ocorre em todo o texto.\n",
        "count = CountVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
        "# fit_transform -> Aprenda o dicionário de vocabulário e retorne a matriz documento-termo.\n",
        "#       Isso é equivalente a fit seguido de transformação, mas implementado de forma mais eficiente.\n",
        "count_matrix = count.fit_transform(smd['soup'])"
      ],
      "metadata": {
        "id": "IiozYGQYUmcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcule a similaridade de cosseno entre as amostras em X e Y.\n",
        "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
      ],
      "metadata": {
        "id": "V6wP39TEeGb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma coluna index contendo os indices do df - reset_index() -> Redefina o índice ou um nível dele.\n",
        "smd = smd.reset_index()\n",
        "# Cria uma serie com os titulos \n",
        "titles = smd['title']\n",
        "# Faço o mapa reverso onde o id é o titulo e os valores são o id do filme\n",
        "# Series -> Array unidimensional com rótulos de eixo (incluindo séries temporais).\n",
        "indices = pd.Series(smd.index, index=smd['title'])"
      ],
      "metadata": {
        "id": "UtJxKB4libNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices"
      ],
      "metadata": {
        "id": "M88yBvhDNqIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**FILTRAGEM COLABORATIVA**"
      ],
      "metadata": {
        "id": "WsJ3CYWOh8uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader()"
      ],
      "metadata": {
        "id": "YrAFZ3ytiFsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes = pd.read_csv('ratings_small.csv')\n",
        "# ds_avaliacoes vai ser usado no KNN\n",
        "ds_avaliacoes = avaliacoes\n",
        "avaliacoes.head()"
      ],
      "metadata": {
        "id": "Zc3xgq7siz2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados = Dataset.load_from_df(avaliacoes[['userId', 'movieId', 'rating']], reader)"
      ],
      "metadata": {
        "id": "qz5YIHVFkDet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd = SVD()\n",
        "cross_validate(svd, dados, measures=['RMSE', 'MAE'], verbose=True)"
      ],
      "metadata": {
        "id": "-yyceWdKmlX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = dados.build_full_trainset()\n",
        "svd.fit(trainset)"
      ],
      "metadata": {
        "id": "obrA9q11oJzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avaliacoes[avaliacoes['userId'] == 1]"
      ],
      "metadata": {
        "id": "4YqlJUO3ueRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd.predict(1, 302, 3)"
      ],
      "metadata": {
        "id": "cEekzYgVvvGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FUNÇÕES UTILITARIAS**"
      ],
      "metadata": {
        "id": "zGGsJvP7q2S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método que normaliza valores entre 0 e 1\n",
        "# Recebe uma coluna como serie\n",
        "def normalizacao_valores(serie):\n",
        "  serie_index = serie.index\n",
        "  array = serie.values\n",
        "  y = array.reshape(-1, 1)\n",
        "  scaler = MinMaxScaler(feature_range= (0, 1))\n",
        "  rescaled = scaler.fit_transform(y)\n",
        "  array = rescaled\n",
        "  serie_normalizada = pd.DataFrame(array, index=serie_index)\n",
        "  return serie_normalizada"
      ],
      "metadata": {
        "id": "V7xm46InKJUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui as vezes retorna um int e as vezes retorna uma serie tratei dessa forma\n",
        "def get_index(title):\n",
        "  # Df indices contem o titulo e o código do filme ao lado\n",
        "  idx = indices[title]\n",
        "\n",
        "  if isinstance(idx, pd.Series):\n",
        "    return idx[0]\n",
        "\n",
        "  return idx"
      ],
      "metadata": {
        "id": "6GJliJKTLS4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RECOMENDADOR KNN**  \n",
        "\n",
        "Antes de qualquer coisa, ajustar o Dataset e organizar as colunas que irei utilizar o dataset de exemplo que irei me basear é esse:   \n",
        "(https://github.com/krishnaik06/Recommendation_complete_tutorial/tree/master/KNN%20Movie%20Recommendation)  \n",
        "Assim que estiver em Pedrinhas tenho que deixar o dataset que tenho conforme será utilizado aqui, realizar o pre-processado com os dados do meu Dataset.  \n",
        "***Esse algoritmo utiliza a estratégia de filtragem colaborativa***  \n",
        "Existem dois tipos:\n",
        "* Baseado em itens;   \n",
        "* Baseado em Usuários.  \n",
        "\n",
        "***No nosso caso iremos utilizar a filtragem colaborativa baseado em usuários***"
      ],
      "metadata": {
        "id": "SWIVcfrHN_V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendacao_KNN(usuarioId, ds_filmes=ds_filmes, ds_links=ds_links, ds_avaliacoes=ds_avaliacoes):\n",
        "\n",
        "  # Importando dataset\n",
        "  # ds_filmes = pd.read_csv('movies_metadata.csv', dtype={'imdb_id':\"string\"})\n",
        "  # ds_links = pd.read_csv('links_small.csv', dtype={'movieId':\"Int64\",'imdbId':\"Int64\",'tmdbId':\"Int64\"})\n",
        "  # ds_avaliacoes = pd.read_csv('ratings_small.csv')\n",
        "\n",
        "  # Cria serie com tmdbId não nulos de DS_Links\n",
        "  # serie_tmdbid_ds_links = ds_links[ds_links['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
        "\n",
        "  # Remoção de linhas mal formatadas \n",
        "  # ds_filmes = ds_filmes.drop([19730, 29503, 35587])\n",
        "\n",
        "  # Converte o tipo da coluna\n",
        "  # ds_filmes['id'] = ds_filmes['id'].astype('int')\n",
        "\n",
        "  # Criando serie com filmes filtrando por serie_tmdbid_ds_links\n",
        "  # ds_filmes = ds_filmes[ds_filmes['id'].isin(serie_tmdbid_ds_links)]\n",
        "\n",
        "  # Verificando imdbids nulos\n",
        "  ds_filmes[ds_filmes['imdb_id'].isnull()]\n",
        "\n",
        "  # Verificando ids nulos\n",
        "  ds_filmes[ds_filmes['id'].isnull()]\n",
        "\n",
        "  # Extraindo coluna imdbId para pegar o código do filme em links\n",
        "  ds_filmes['imdbId'] = ds_filmes['imdb_id'].apply(lambda x: x if pd.isna(x) else str(x)[2:])\n",
        "\n",
        "  # Alterando tipo da coluna\n",
        "  ds_filmes['imdbId'] = ds_filmes['imdbId'].astype('int')\n",
        "\n",
        "  # Merge pegando os movieIds de Links\n",
        "  ds_filmes = pd.merge(ds_filmes, ds_links, on='imdbId')\n",
        "\n",
        "  # Removendo a coluna tmdbId\n",
        "  ds_filmes.drop(['tmdbId'], axis=1, inplace=True)\n",
        "  \n",
        "  # Para fazer a filtragem colaborativa o que me interessa é o Id do Filme e o titulo\n",
        "  # Selecionando/filtrandos as colunas que irei utilizar \n",
        "  ds_filmes = ds_filmes[['movieId', 'title']]\n",
        "\n",
        "  # Filtrando as colunas que preciso\n",
        "  ds_avaliacoes = ds_avaliacoes[['userId', 'movieId', 'rating']]\n",
        "  \n",
        "  # Juntar as duas bases, semelhante ao join no SQL \n",
        "  df_filmes_avaliacoes = pd.merge(ds_filmes, ds_avaliacoes, on='movieId')\n",
        "  \n",
        "\n",
        "  # Pega o id do usuário e coloca como indice da coluna e pivotar a tabela \n",
        "  # Onde os titulos apareçam em cima e as avaliações serão os valores \n",
        "  df_recommender = df_filmes_avaliacoes.pivot_table(index='userId', columns='title', values='rating').fillna(0)\n",
        "  \n",
        "\n",
        "  # Modelo dos vizinhos próximos - KNN\n",
        "  # Distância do cosseno não sofre muito com a maldição da dimensionalidade\n",
        "  # Instancia o modelo KNN, usando a metrica do cosseno(hiperparametros)\n",
        "  modelo_knn = NearestNeighbors(metric='cosine')\n",
        "  # Calcula todas as distâncias em relação aos vizinhos próximos\n",
        "  modelo_knn.fit(df_recommender)\n",
        "\n",
        "  # Quantidade de vizinhos mais próximos que quero\n",
        "  qtde_vizinhos = 4\n",
        "\n",
        "  # Recupera a linha que o usuário se encontra\n",
        "  # Usuario que eu quero recomendar algo\n",
        "  idx_usuario_knn = df_recommender.index.get_loc(df_recommender.loc[usuarioId].name)\n",
        "  # Quando chamar o modelo de KNN preciso saber a distância dos vizinhos próximos\n",
        "  # E quais são os indices vizinhos próximos\n",
        "  # Irei passar no parâmetro de kneighbors() o registro que quero usar para puxar\n",
        "  # Vizinho mais próximo - Fiz uma mudança ao invés de iloc usei loc\n",
        "  distancia_vizinhos, indices_vizinhos = modelo_knn.kneighbors(df_recommender.iloc[idx_usuario_knn].values.reshape(1, -1), n_neighbors=qtde_vizinhos)\n",
        "\n",
        "  usuario = df_recommender.index[idx_usuario_knn]\n",
        "\n",
        "  # Cria a lista que irá conter os dataframes\n",
        "  dfs_vizinhos_proximo = []\n",
        "\n",
        "  # For para percorrer cada um da lista \n",
        "  # Usei o flatter para remover uma dimensão \n",
        "  for i in range(0, len(distancia_vizinhos.flatten())):\n",
        "    # Pula o primeiro elemento pois vai ser ele mesmo\n",
        "    if i == 0:\n",
        "      ds_usuario_knn = df_recommender.loc[usuario].to_frame()\n",
        "      dfs_vizinhos_proximo.append(ds_usuario_knn)\n",
        "    else:\n",
        "      # Localiza o vizinho mais próximo em df_recommender\n",
        "      vizinho_proximo = df_recommender.index[indices_vizinhos.flatten()[i]]\n",
        "      # Adiciona o vizinho próximo a lista dos dataframes\n",
        "      dfs_vizinhos_proximo.append(df_recommender.loc[vizinho_proximo].to_frame())\n",
        "  \n",
        "\n",
        "  # Pegando o indice dos vizinhos mais próximos\n",
        "  idx_vizinhos_prox = [col for i in range(len(dfs_vizinhos_proximo)) for col in dfs_vizinhos_proximo[i] if i != 0]\n",
        "  \n",
        "  # Faz o merge da dataframe do usuário com seus vizinhos\n",
        "  ds_titulos = reduce(lambda df_esq, df_dir: pd.merge(df_esq, df_dir, on=['title']), dfs_vizinhos_proximo)\n",
        "\n",
        "  # Ordena de forma descrescente pelos vizinhos mais próximos\n",
        "  ds_titulos = ds_titulos.sort_values(by=idx_vizinhos_prox, ascending=False)\n",
        "  \n",
        "  # Filtrar todos os titulos do vizinho que foram > 0 e onde usuário não assistiu\n",
        "  ds_titulos = ds_titulos[((ds_titulos[idx_vizinhos_prox[0]] > 0) | (ds_titulos[idx_vizinhos_prox[1]] > 0) | (ds_titulos[idx_vizinhos_prox[2]] > 0)) & (ds_titulos[usuario] == 0)]\n",
        "  \n",
        "  # Criando e calculando a média \n",
        "  ds_titulos['Media'] = (ds_titulos[idx_vizinhos_prox[0]] + ds_titulos[idx_vizinhos_prox[1]] + ds_titulos[idx_vizinhos_prox[2]]) / len(idx_vizinhos_prox)\n",
        "\n",
        "  # Resetando o indice\n",
        "  ds_titulos.reset_index(inplace=True)\n",
        "\n",
        "  # Atribui a média os valores de média normalizados \n",
        "  ds_titulos['est'] = normalizacao_valores(ds_titulos['Media'])\n",
        "\n",
        "  # Filtrando as colunas que irei devolver ao método híbrido \n",
        "  titulos_recomendacao_KNN = ds_titulos[['title', 'est']]\n",
        "  titulos_recomendacao_KNN = titulos_recomendacao_KNN.sort_values(by=['est'], ascending=False)\n",
        "\n",
        "\n",
        "  return titulos_recomendacao_KNN.head(10)\n"
      ],
      "metadata": {
        "id": "bfHx2T9YZULG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testando Recomendador KNN**"
      ],
      "metadata": {
        "id": "6ixpSY3fqLnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recomendacao_KNN(1)"
      ],
      "metadata": {
        "id": "nvn9UBY8FdWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**RECOMENDADOR HÍBRIDO**"
      ],
      "metadata": {
        "id": "chB6MWH5CsQs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gh8Cbcg5JlB"
      },
      "outputs": [],
      "source": [
        "def convert_int(x):\n",
        "  try:\n",
        "    return int(x)\n",
        "  except:\n",
        "    return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando o arquivo que contem os ids dos filmes, selecionando \n",
        "# as colunas 'movieId', 'tmdbId'\n",
        "id_map = pd.read_csv('links_small.csv')[['movieId', 'tmdbId']]\n",
        "# Converte a coluna id_map['tmdbId'] para inteiro\n",
        "id_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)\n",
        "# Mudando os nomes da coluna tmdbId para id\n",
        "id_map.columns = ['movieId', 'id']\n",
        "# Fazendo o merge de id_map com SMD\n",
        "id_map = id_map.merge(smd[['title', 'id']], on='id').set_index('title')"
      ],
      "metadata": {
        "id": "jLu7KTnq7YHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_map = id_map.set_index('id')"
      ],
      "metadata": {
        "id": "lvbqAAbO70Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Junta e soma as estimativas de cada dataframe \n",
        "def agrupa_recomendacoes(dataframe1, dataframe2):\n",
        "  dfs_concatenados = pd.concat([dataframe1, dataframe2], ignore_index=True)\n",
        "  dfs_agrupados = dfs_concatenados.groupby('title')[['est']].mean()\n",
        "  # dfs_agrupados = dfs_concatenados.groupby('title')['est'].sum()\n",
        "\n",
        "  dfs_agrupados = dfs_agrupados.sort_values('est', ascending=False)\n",
        "  dfs_agrupados = dfs_agrupados.reset_index()\n",
        "\n",
        "  return dfs_agrupados\n"
      ],
      "metadata": {
        "id": "efkhWLfILStO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendador_hibrido(userId, title):\n",
        "\n",
        "  if isinstance(userId, int) and isinstance(title, str):\n",
        "\n",
        "    if (userId in avaliacoes['userId'].values) and (title in id_map.index) :\n",
        "      \n",
        "      idx = get_index(title)\n",
        "\n",
        "      titulos_recomendados_KNN = recomendacao_KNN(userId)\n",
        "  \n",
        "      sim_scores = list(enumerate(cosine_sim[int(idx)]))\n",
        "      sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "      sim_scores = sim_scores[1:26]\n",
        "      movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "      movies = smd.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'year', 'id']]\n",
        "      movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, indices_map.loc[x]['movieId']).est)\n",
        "      movies['est'] = normalizacao_valores(movies['est'])\n",
        "      movies = movies[['title', 'est']]\n",
        "\n",
        "      movies = movies.sort_values('est', ascending=False)\n",
        "\n",
        "      movies = movies.head(10)\n",
        "\n",
        "      recomendacao_hibrida = agrupa_recomendacoes(titulos_recomendados_KNN, movies)\n",
        "\n",
        "      return recomendacao_hibrida\n",
        "    \n",
        "    else:\n",
        "      print('Erro: O id do usuário ou nome do filme não consta no dataset')\n",
        "  else:\n",
        "    print('Algo inesperado aconteceu. Tente novamente!')"
      ],
      "metadata": {
        "id": "EJcW2d2_71_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recomendador_hibrido(1, \"Avatar\")"
      ],
      "metadata": {
        "id": "RVuKJol2mILS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recomendador_hibrido(500, 'Avatar')"
      ],
      "metadata": {
        "id": "VjlrHmrTmO_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}